---
title: "Final Project Presentation"
author: "Tianlang Yang"
date: "2018/05/04"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

##Introduction

In order to figure out what Internet users are talking about and how they feel about Coachella, this report analyzed data collected from twitter a week after the Coachella 2018, mainly focus on:
  
  1.The frequency of words mentioned by users, showing by Word Cloud.
  
  2.Visualization of sentiments towards the music festival among different hashtags and different locations
  
  3.Statistical analysis to generate the population.
  
```{r package setup, message=FALSE, warning=FALSE, include=FALSE}

require(devtools)
require(ggmap)
require(plyr)
require(stringr)
require(dplyr)
require(ggplot2)
require(reshape)
require(tm)
require(RJSONIO)
require(wordcloud)
require(grid)
require(gridExtra)
require(tidyr)
require(tidyverse)
require(tidytext)
require(lubridate)
require(plyr)
require(shiny)
require(maps)
require(leaflet)
require(rsconnect)

```

## Data summary
After gathering data from twitter API and deleting the tweets with no location data, there are:
638 observations for #Coachella2018, 
620 observations for #Coachella
and 698 observations for #Beychella, together 1956 observations.

```{r read data, message=FALSE, warning=FALSE, include=FALSE}

total <- read.csv("total.csv",row.names = 1)
data3 <- read.csv("data3.csv",row.names = 1)
data2 <- read.csv("data2.csv", row.names = 1)
data1 <- read.csv("data1.csv",row.names = 1)
```

```{r text clean, message=FALSE, warning=FALSE, include=FALSE}
#Define text clean function
CleanTweets <- function(tweets)
  {
    tweets = gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", tweets)
    tweets = gsub("@\\w+", "", tweets)
    tweets = gsub("[[:punct:]]", "", tweets)
    tweets = gsub("[[:digit:]]", "", tweets)
    tweets = gsub("http\\w+", "", tweets)
    tweets = gsub("[ \t]{2,}", "", tweets)
    tweets = gsub("^\\s+|\\s+$", "", tweets)
    tweets = gsub("amp", "", tweets)
    # define "tolower error handling" function
    try.tolower = function(x)
    {
      y = NA
      try_error = tryCatch(tolower(x), error=function(e) e)
      if (!inherits(try_error, "error"))
        y = tolower(x)
      return(y)
    }
    
    tweets = sapply(tweets, try.tolower)
    tweets = tweets[tweets != ""]
    names(tweets) = NULL
    return(tweets)
  }

#Clean all the text
tweets1 <- gettext(data1$text)  # tweets of "#Coachella2018"
tweets2 <- gettext(data2$text)  # tweets of "#Coachella"
tweets3 <- gettext(data3$text)  # tweets of "#Beychella"
tweets4 <- gettext(total$text)  # all tweets together

```

```{r wordcloud function, message=FALSE, warning=FALSE, include=FALSE}
library(wordcloud)
library(tm)
library(tmap)
  wordcloudentity<-function(tweets)
  {
    tweetCorpus<-Corpus(VectorSource(CleanTweets(tweets)))
    tweetTDM<-TermDocumentMatrix(tweetCorpus,control=list(removePunctuation=TRUE
    ,stopwords=c('Coachella', 'Beychella',stopwords('english')), 
    removeNumbers=TRUE,tolower=TRUE))
    tdMatrix <- as.matrix(tweetTDM) # creating a data matrix
    
    sortedMatrix<-sort(rowSums(tdMatrix),decreasing=TRUE) # calculate row sum of                       each term and sort in descending order (high freq to low)
   cloudFrame<-data.frame(word=names(sortedMatrix),freq=sortedMatrix)#extracting
   #names from named list in prev command and binding together into a dataframe 
   #with frequencies
     wcloudentity<-wordcloud(cloudFrame$word,cloudFrame$freq,max.words=200, colors=brewer.pal(8,"Dark2"),scale=c(8,1), random.order=FALSE)
 return(wcloudentity)
  }
```

## Wordcloud for total data

```{r wordcloud total, echo=FALSE, message=FALSE, warning=FALSE}
#Wordcloud for total data

wordtotal <- wordcloudentity(tweets4)

```
From this wordcloud of total data, we can see word "Beychella" is mentioned a lot. "Great" is also mentioned a lot which means people are enjoying the festival. 


## Wordcloud for hashtag #Coachella2018
```{r wordcloud1, echo=FALSE, message=FALSE, warning=FALSE}
#Wordcloud for #Coachella2018
wordcloud1 <- wordcloudentity(tweets1)

```
The wordcloud for #Coachella2018 focus on words like: "great", "stagecoach"(which is a California's country music festival during Coachella music festival), and "different". This means that most people enjoy the music festival, but there're still decent amount of people have ambivalent feelings about this year's festival by descibing it as "different".

## Wordcloud for key words #Coachella

```{r wordcloud2, echo=FALSE, message=FALSE, warning=FALSE}
#Wordcloud for #Coachella
wordcloud2 <- wordcloudentity(tweets2)

```
Tweets under key words #Coachella were more positive comparing to tweets under key words #Coachella2018. More positive words like: "winners", "invest", and "highest". 


## Wordcloud for hashtag #Beychella

```{r wordcloud3, echo=FALSE, message=FALSE, warning=FALSE}
#Wordcloud for #Beychella
wordcloud3 <- wordcloudentity(tweets3)

```
Tweets under this hashtag doesn't have much sentimental words. However, words like "everybodymad"("mad" here should be excitment), "lovely", "like", and "crying" (here should be crying for the happiness and excitment) show that people have positive snetiment toward Beyonce's performance on Coachella 2018. 



##Histogram of sentiment

```{r sentiment plot, echo=FALSE, message=FALSE, warning=FALSE}
library(tidytext)
#remove some "stopwords"
reg <- "([^A-Za-z\\d#@']|'(?![A-Za-z\\d#@]))"
tweet_words <- total %>%
  filter(!str_detect(text, '^"')) %>%
  mutate(tweets = text) %>%
  mutate(text = str_replace_all(text, "https://t.co/[A-Za-z\\d]+|&amp;", "")) %>%
  unnest_tokens(word, text, token = "regex", pattern = reg) %>%
  filter(!word %in% stop_words$word,
         str_detect(word, "[a-z]"))
#find the most common words in tweets
commonword <- tweet_words %>%
  dplyr::count(word, sort = TRUE) %>%
  head(20) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_bar(stat = "identity") +
  coord_flip()

bing <- get_sentiments("bing")
bing_word_counts <- tweet_words %>%
  inner_join(bing) %>%
  dplyr::count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts <- bing_word_counts[-1, ]

#remove the top key words and then plot words
bing_word_counts %>%
  filter(n > 20) %>%
  mutate(n = ifelse(sentiment == "negative", -n, n)) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ylab("Sentiment")
```

The proportion of positive words is larger, and their sentiments are stronger, which means people are more likely to enjoy the music festival instead of perplex and upset by the chaos and crowd. 



## Map with sentiment


```{r map sentiment, echo=FALSE, message=FALSE, warning=FALSE}
#Get the US map
USmap = ggmap(get_googlemap(center =as.numeric(geocode("United States")),
                            scale=2, zoom=4), extent="device") 

#Draw map for total data
map1<- USmap +
  geom_point(aes(x=lon, y=lat), col=ifelse(((total$score>=0)),"red", "blue"), data=total, alpha=0.4, size=total$absolute_score) +
  scale_size_continuous(range=total$score)+
  ggtitle("Sentiment map for total data set")
map1
```
Here red represents positive sentiment and blue represent negative sentiment.
There seems to be more users located on the east coast than on the west coast. Also, the color for tweets from the west coast is darker, especially in south California which means people there have more positive sentiment.

## Mapping under #Coachella2018
```{r map2, echo=FALSE, message=FALSE, warning=FALSE}
# mapping under #Coachella2018
map2 <- USmap +
  geom_point(aes(x=lon, y=lat), col=ifelse(((data1$score>=0)),"red", "blue"), data=data1, alpha=0.4, size=data1$absolute_score) +
  scale_size_continuous(range=data1$score)+
  ggtitle("Sentiment map for #Coachella2018")
map2
```


## Mapping under #Coachella
```{r map3, echo=FALSE, message=FALSE, warning=FALSE}
# mapping under #Coachella
map3 <- USmap +
  geom_point(aes(x=lon, y=lat), col=ifelse(((data2$score>=0)),"red", "blue"), data=data2, alpha=0.4, size=data2$absolute_score) +
  scale_size_continuous(range=data2$score)+
  ggtitle("Sentiment map for #Coachella")
map3
```


## Mapping under #Beychella
```{r map4, echo=FALSE, message=FALSE, warning=FALSE}
# mapping under #Beychella
map4 <- USmap +
  geom_point(aes(x=lon, y=lat), col=ifelse(((data3$score>=0)),"red", "blue"), data=data3, alpha=0.4, size=data3$absolute_score) +
  scale_size_continuous(range=data3$score)+
  ggtitle("Sentiment map for #Beychella")
map4
```





